\subsection{Разработка структуры компонента для обучения нейросети и предсказания интересов}

В данном разделе будет детально рассмотрена структура модуля, его функции и алгоритмы функционирования. Кроме того, будут рассмотрены наиболее популярные методы предсказания, будет обоснован выбор наиболее  


\subsubsection{Определение ключевых функций}

Разрабатываемый модуль должен предсказывать интересы людей на основе их автомобиля и возраста. Интересы разбиваются на различные группы, например:

\begin{itemize}
    \item искусство;
    \item спорт;
    \item книги/фильмы;
    \item наука;
    \item путешествия;
    \item кулинария;
    \item политика.
\end{itemize}

Модуль должен предсказать вероятность того, есть ли у клиента интересы в этих областях, например, 10\% - искусство, 78\% - спорт и так далее.

Для определения разделения на области интересов могут использоваться любые вопросы, то есть можно учитывать интересы людей, относящиеся к другим областям, например, музыка, животные и т.п.

При проектировании модуля для примера используется распределение, который было определено при проектировании модуля, направленног на сбор данных. Ниже приведен список вопросов, которые там применялись:
\begin{itemize}
    \item интересуетесь ли вы искусством (картины, скульптура, музыка и т.д.);
    \item занимаетесь ли вы спортом или физической активностью;
    \item любите ли вы чтение книг или просмотр фильмов;
    \item интересуетесь ли вы наукой и технологиями;
    \item увлекаетесь ли вы путешествиями и открытием новых мест;
    \item является ли для вас кулинария или готовка хобби;
    \item интересуетесь ли вы политикой и общественными вопросами;
    \item так же на бланке присутствует поле, в котором опрашиваемый должен указать свой возраст.
\end{itemize}

Точность предсказания должна быть не ниже 80\%.

\subsubsection{Выбор метода}

В этом разделе будут описаны наиболее популярные методы, которые используются для предсказания чего-либо, а также будет обоснован выбор наиболее подходящего.

\paragraph{Описание искусственных нейронных сетей}

Человеческий мозг великолепно справляется с задачами по распознаванию образов, опережая в этом даже самые передовые компьютеры. Это объясняется особенностями обработки информации в мозге, которые значительно отличаются от методов, используемых в цифровых устройствах. Мозг человека - это сложная, нелинейная и параллельная система обработки данных. Он умело организовывает свои структурные компоненты для успешного решения разнообразных задач, таких как распознавание образов, превосходя при этом даже самые мощные компьютеры в скорости обработки информации \refref{ref:neuron}.

Искусственная нейронная сеть – это сложный параллельный процессор, который состоит из множества элементарных блоков, называемых нейронами, предназначенных для обработки информации. Эти нейроны накапливают опыт и передают его для дальнейшей обработки \refref{ref:neuron}.

Ниже приведены некоторые преимущества нейронных сетей:
\begin{itemize}
    \item нелинейность, что позволяет моделировать сложные отношения в данных;
    \item преобразование входящей информации в выходные результаты;
    \item адаптивность, позволяющая сети настраиваться под различные задачи;
    \item понятность ответов, делая выводы из сети более интерпретируемыми;
    \item учёт контекстной информации для более точных прогнозов;
    \item способность к отказоустойчивости, что позволяет сохранять работоспособность даже при некоторых повреждениях;
    \item единообразный подход к анализу и проектированию.
\end{itemize}


Обучение нейронной сети, или ее настройка, представляет собой процесс изменения свободных параметров сети через моделирование ее взаимодействия с окружающей средой. Тип обучения определяется выбором метода для определения характеристик.

Этот процесс настройки можно описать следующей последовательностью действий:
\begin{enumerate}
    \item cеть получает стимулы извне;
    \item свободные параметры сети подвергаются изменениям;
    \item после изменений во внутренней структуре нейронная сеть реагирует на входные стимулы по-новому.
\end{enumerate}

Алгоритм обратного распространения, известный как один из основных методов обучения, находит свое место среди разнообразных алгоритмов обучения. Наиболее известным и широко применяемым из них является алгоритм обратного распространения. Этот метод нацелен на минимизацию разницы между реальными выходными значениями нейронной сети (ANN) и желаемыми выходами. Его детальное описание можно найти в источниках \refref{ref:back-error}.

Суть обучения через алгоритм обратного распространения заключается в переводе задачи отображения от входных данных к выходным значениям (путем использования набора примеров) в установку оптимальных синаптических весов и порогов для многослойного персептрона. Процесс настройки сети можно рассматривать как выбор наилучшей модели из набора "кандидатов" структур, основанный на определенных критериях \refref{ref:back-error}.

\begin{figure}[h!]
    \centering
    \vspace{\toppaddingoffigure}
    \includegraphics[width=0.7\textwidth]{neuron}
    \caption{Нелинейная модель нейрона}
    \label{f:neuron}
\end{figure}

Нейрон, в контексте нейронных сетей, представляет собой ключевую единицу обработки информации \refref{ref:neuron-model}. На рисунке~\ref{f:neuron} представлена модель нейрона, которая лежит в основе искусственных нейронных сетей. Эта модель включает в себя три основных компонента.

Ансамбль синапсов состоит из множества связей, каждая из которых имеет свой собственный вес или силу. Сумматор суммирует входные сигналы, учитывая их веса, которые связаны с соответствующими синапсами нейрона. Функция активации контролирует выходной сигнал нейрона, ограничивая его амплитуду \refref{ref:neuron-model}.

Модель нейрона также может включать пороговый элемент, обозначаемый символом  $b_k$, который влияет на функцию активации, регулируя входной сигнал.

Математически, работу нейрона можно описать следующими уравнениями

\begin{gather}
    u_k = \displaystyle\sum_{j=1}^{m} w_{kj} * x_j, \\
    y_k = \phi * (u_k + b_k)
\end{gather}

где $x_1, x_2, ... , x_m$ - входные сигналы 

$w_{k1}, w_{k2}, ... , w_{km}$ - синаптические весы нейрона $k$

$u_k$ - линейная комбинация входных действий (выход линейного комбинатора)

$b_k$- порог; $\phi()$ – функция активации

$y_k$ является выходным сигналом нейрона.

Постсинаптический потенциал рассчитывается следующим образом
\begin{gather}
    v_k = u_k + b_k
\end{gather}

Функции активации - это особые инструменты, которые определяют, какой будет выходной сигнал нейрона в ответ на воздействие на него окружающей области. Давайте рассмотрим несколько различных функций активации. Кроме перечисленных, существует еще множество других функций активации \refref{ref:neuron-model}.

Одной из таких функций является сигмовидная функция. Она примечательна тем, что быстро переходит от линейного к нелинейному поведению. Логистическая функция является примером сигмовидной функции и может быть представлена следующим образом
\begin{gather}
    f(x) = \frac{1}{1 + e^{-x}}
\end{gather}

\paragraph{Наивный байесовский классификатор}

Наивный байесовский классификатор (Naive Bayes classifier) – это вероятностный алгоритм, основанный на теореме Байеса. Он делает строгое (наивное) предположение о том, что признаки независимы друг от друга для каждого заданного класса. Это предположение значительно упрощает процесс классификации, так как позволяет оценивать одномерные вероятностные плотности вместо многомерных \refref{ref:nbc}.

В этом контексте одномерная вероятностная плотность означает оценку вероятности каждого отдельного признака при условии их независимости, тогда как многомерная плотность оценивает вероятность комбинации всех признаков, предполагая их взаимозависимость. Классификатор называется наивным именно потому, что такое предположение значительно упрощает вычисления и улучшает эффективность алгоритма. Однако, на практике, предположение о независимости признаков часто не соответствует действительности, что может существенно снизить качество прогнозов в некоторых случаях \refref{ref:nbc}.

Сама же формула Байеса выглядит следующим образом
\begin{gather}
    P(A|B) = \frac{P(B|A) * P(A)}{P(B)}
\end{gather}

где $P(A|B)$ — апостериорная вероятность события A при условии выполнения события B

$P(B|A)$ — условная вероятность события B при условии выполнения события A

$P(A)$ и $P(B)$ — априорные вероятности событий A и B соответственно.

% \begin{itemize}
%     \item $P(A|B)$ — апостериорная вероятность события A при условии выполнения события B;
%     \item $P(B|A)$ — условная вероятность события B при условии выполнения события A;
%     \item $P(A)$ и $P(B)$ — априорные вероятности событий A и B соответственно.
% \end{itemize}

А в контексте машинного обучения формула Байеса приобретает следующий вид
\begin{gather}
    P(y_k|X) = \frac{P(X|y_k) * P(y_k)}{P(X)}
\end{gather}

где $P(yk|X)$ — апостериорная вероятность принадлежности образца к классу $y_k$ с учётом его признаков X

$P(X|yk)$ — правдоподобие, то есть вероятность признаков X при заданном классе $y_k$

$P(yk)$ — априорная вероятность принадлежности случайно выбранного наблюдения к классу $y_k$

$P(X)$ — априорная вероятность признаков X.


% \begin{itemize}
%     \item $P(yk|X)$ — апостериорная вероятность принадлежности образца к классу $y_k$ с учётом его признаков X;
%     \item $P(X|yk)$ — правдоподобие, то есть вероятность признаков X при заданном классе $y_k$;
%     \item $P(yk)$ — априорная вероятность принадлежности случайно выбранного наблюдения к классу $y_k$;
%     \item $P(X)$ — априорная вероятность признаков X.
% \end{itemize}

Если объект описывается не одним, а несколькими признаками $X_1, X_2, ... , X_n$, то формула принимает вид

\begin{gather}
    P(y_k|X_1, X_2, ... , X_n) = \frac{P(y_k) * \displaystyle\prod_{i=1}^{n}{P(X_i|y_k)}}{P(X_1, X_2, ... , X_n)}
\end{gather}


На практике основное внимание уделяется числителю формулы, так как знаменатель зависит только от признаков и не влияет на класс. Поэтому его часто опускают при сравнении вероятностей различных классов. В результате правило классификации сводится к выбору класса с максимальной апостериорной вероятностью.

\begin{gather}
    y_k \propto arg max P(y_k) \displaystyle\prod_{i=1}^{n}{P(X_i|y_k)}
\end{gather}

Для оценки параметров модели, то есть вероятностей $P(y_k)$ и $P(X_i|y_k)$, обычно применяется метод максимального правдоподобия, который в данном случае основан на частотах встречаемости классов и признаков в обучающей выборке.



\paragraph{Логистическая регрессия}

Логистическая регрессия – это метод анализа данных, который применяет математические методы для выявления взаимосвязей между двумя переменными. Эти взаимосвязи затем используются для прогнозирования значения одной переменной на основе другой. Обычно результаты прогноза имеют ограниченное количество возможных исходов, например, "да" или "нет" \refref{ref:log-reg}.

Модель логистической регрессии имеет несколько составляющих:
\begin{itemize}
    \item уравнения. В математике уравнения выражают зависимость между двумя переменными, например, $x$ и $y$. Эти уравнения позволяют построить график по осям $x$ и $y$, подставляя различные значения $x$ и $y$. Например, если построить график для уравнения $y = 2 * x$, получится прямая линия. Поэтому такие уравнения называют линейными \refref{ref:log-reg};
    \item переменные. В статистике переменные – это факторы или атрибуты данных, значения которых могут изменяться. В анализе некоторые переменные являются независимыми или объясняющими и служат причиной результата. Другие переменные зависят от первых и называются зависимыми переменными или переменными отклика. Логистическая регрессия исследует, как независимые переменные влияют на зависимую, анализируя их исторические значения. В нашем примере x является независимой переменной, предиктором или объясняющей переменной, потому что ее значение известно. А y является зависимой переменной, результатом или переменной отклика, так как ее значение необходимо предсказать \refref{ref:log-reg};
    \item функция логистической переменной. Логистическая регрессия – это статистическая модель, использующая логистическую или логит-функцию в качестве уравнения между $x$ и $y$. Логит-функция отображает y как сигмоидальную функцию от $x$ \refref{ref:log-reg}.
\end{itemize}

\paragraph{Обоснование выбора метода}

Ниже приведены достоинства и недостатки рассмотренных методов.

Плюсы логистической регрессии:
\begin{itemize}
    \item простота реализации и интерпретации;
    \item эффективность при линейной разделяющей гиперплоскости;
    \item меньшая склонность к переобучению на небольших наборах данных;
    \item хорошо работает с линейно разделимыми данными.
\end{itemize}

Минусы логистической регрессии:
\begin{itemize}
    \item ограничение на моделирование нелинейных зависимостей;
    \item ограниченная способность к обработке больших объемов данных;
    \item не учитывает взаимосвязи между признаками.
\end{itemize}


Плюсы наивного байесовского классификатора:
\begin{itemize}
    \item простота и скорость обучения;
    \item эффективность на небольших наборах данных;
    \item меньшая склонность к переобучению.
\end{itemize}

Минусы наивного байесовского классификатора:
\begin{itemize}
    \item предположение о независимости признаков может быть слишком сильным и нереалистичным;
    \item не способен улавливать сложные взаимосвязи между признаками;
    \item требует хорошо подготовленных данных.
\end{itemize}

Плюсы нейронных сетей:
\begin{itemize}
    \item способность моделировать сложные нелинейные зависимости;
    \item автоматическое извлечение признаков из данных;
    \item гибкость и адаптивность к различным типам данных и задачам;
    \item эффективность на больших объемах данных;
    \item улучшенная производительность на сложных задачах.
\end{itemize}

Минусы нейронных сетей:
\begin{itemize}
    \item требуют большого объема данных для обучения;
    \item сложность интерпретации модели;
    \item большое количество настраиваемых параметров, требующих подбора.
\end{itemize}

Исходя из приведенного выше анализа, нейронные сети выделяются среди других методов машинного обучения благодаря их способности моделировать сложные зависимости и обрабатывать большие объемы данных.

% \subsubsection{Проектирование модуля}

\subsubsection{Структура модуля}

Необходимо сформировать наиболее точное описание разрабатываемого программного обеспечения. Для этого было принято решение о рассмотрении функциональной диаграммы верхнего уровня.

В данном случае в качестве отображения взаимосвязей была выбрана нотация IDEF0. В качестве входов датасет для обучения нейросети, возраст посетителя, модель автомобиля посетителя. В качестве субъекта выступает пользователь и вычислительная машина. Управление задается алгоритмами обучения нейронной сети и алгоритмом работы с обученной моделью. К выходным данным будут относиться предсказанные интересы посетителя.

Контекстная диаграмма IDEF0 представлена на рисунке~\ref{f:neuro-struct}

\begin{figure}[h!]
    \centering
    \vspace{\toppaddingoffigure}
    \includegraphics[width=0.5\textwidth]{neuro-struct}
    \caption{Контекстная диаграмма IDEF0}
    \label{f:neuro-struct}
\end{figure}

Детализирующая функциональная диаграмма более подробно раскрывает функциональную диаграмму верхнего уровня: описывает взаимодействия и связи процессов, происходящих внутри системы. На ней можно увидеть, какие процессы взаимосвязаны и что между ними общего.

На детализирующей функциональной диаграмме показаны следующие этапы:
\begin{itemize}
    \item обучение нейросети. На вход поступает датасет, а на выходе получается обученная модель;
    \item определение интересов. На вход поступает обученная модель, а на выход предсказанные интересы.
\end{itemize}

Детализированная контекстная диаграмма представлена на рисунке~\ref{f:neuro-struct-det}

\begin{figure}[h!]
    \centering
    \vspace{\toppaddingoffigure}
    \includegraphics[width=0.8\textwidth]{neuro-struct-det}
    \caption{Детализированная контекстная диаграмма IDEF0}
    \label{f:neuro-struct-det}
\end{figure}

Таким образом, разрабатываемый модуль будет состоять из двух основных компонентов: «Обучения нейросети», «Определение интересов».

% Так же стоит определить формат датасета, который используется для обучения нейросети. В него входит вся информация, которую можно получить с помощью описанного выше модуля для сбора данных. Следовательно, датасет имеет следующие поля:

% \begin{itemize}
%     \item model: модель автомобиля;
%     \item age: возраст;
%     \item art: интерес к искусству;
%     \item sport: интерес к спорту;
%     \item book/film: интерес к фильмам и книгам;
%     \item science: интерес к науке и технологиям;
%     \item travel: интерес к путешествиям;
%     \item cooking: интерес к готовке;
%     \item politics: интерес к политике.
% \end{itemize}


\subsubsection{Алгоритм обучения нейронной сети}

В этом разделе рассматривается общий алгоритм обучения нейронных сетей, который включает в себя загрузку, предварительную обработку и разделение данных, определение архитектуры модели, обучение, оценку производительности и настройку гиперпараметров. Понимание этого алгоритма позволит лучше понять процесс создания и настройки нейронных сетей для решения конкретных задач машинного обучения. Сам алгоритм представлен на рисунке~\ref{f:neuro-learn}

\begin{figure}[h!]
    \centering
    \vspace{\toppaddingoffigure}
    \includegraphics[width=0.5\textwidth]{neuro-learn}
    \caption{Алгоритм обучения сети}
    \label{f:neuro-learn}
\end{figure}

Рассмотрим алгоритм подробнее:
\begin{enumerate}
    \item загрузка данных. Начинаем с загрузки данных из источника, чаще всего из файлов CSV, баз данных или других источников данных;
    \item предварительная обработка данных. Перед тем как данные попадут в модель, их необходимо подготовить. Это может включать в себя удаление или заполнение отсутствующих значений, преобразование категориальных переменных в числовые (например, с помощью кодирования One-Hot), нормализацию числовых данных и т.д.;
    \item разделение данных. Для оценки модели данные обычно разделяются на обучающий и тестовый наборы. Обучающий набор используется для обучения модели, а тестовый - для оценки ее производительности;
    \item определение архитектуры модели. Решается, какая будет архитектура нейронной сети: сколько слоев и скрытых нейронов в каждом слое, какие функции активации использовать, будет ли применяться метод регуляризации (например, Dropout), и т.д.;
    \item определение функции потерь и оптимизатор. Выбирается функция потерь (например, кросс-энтропия для классификации) и оптимизатор (например, стохастический градиентный спуск, Adam и т.д.), которые будут использоваться в процессе обучения;
    \item обучение модели. Модель обучается на обучающем наборе данных. Обычно это включает в себя несколько эпох обучения, где каждая эпоха представляет собой один проход по всем обучающим данным;
    \item оценка производительности модели. После завершения обучения модель оценивается на тестовом наборе данных, чтобы определить ее производительность и обобщающую способность;
    \item настройка гиперпараметров. Для улучшения производительности модели может быть выполнен подбор оптимальных гиперпараметров, таких как количество слоев, количество нейронов, скорость обучения и т.д.;
    \item выбор лучшей модели. Выбирается модель с лучшей производительностью на основе метрик оценки, таких как точность (accuracy), F1-мера, и т.д.;
    \item интеграция с обратной связью. Для улучшения обучения и производительности модели могут быть применены различные методы обратной связи, такие как ранняя остановка (Early Stopping), адаптивная скорость обучения и т.д.
\end{enumerate}


\subsubsection{Описаение структуры нейронной сети}

Определение структуры нейронной сети включает в себя выбор архитектуры сети, составление слоев и их параметров. Обычно структура нейронной сети определяется в соответствии с характеристиками входных данных, задачей, которую необходимо решить, и требованиями к производительности и точности.

В данном случае, для решения задачи многоклассовой классификации, используется последовательная модель нейронной сети, что означает, что слои нейронов последовательно соединены друг с другом. Вот общая структура нейронной сети:
\begin{enumerate}
    \item входной слой. Входной слой представляет собой первый слой нейронной сети, который принимает входные данные. В данном случае, размерность входного слоя определяется количеством признаков в данных;
    \item скрытые слои. Скрытые слои представляют собой слои нейронов, которые выполняют преобразование входных данных. Каждый скрытый слой состоит из нескольких нейронов (узлов), количество которых определяется архитектурой сети. Для каждого нейрона в скрытом слое применяется активационная функция (например, ReLU) для введения нелинейности и извлечения признаков из входных данных;
    \item выходной слой. Выходной слой представляет собой последний слой нейронной сети, который генерирует выходные данные. В данном случае, выходной слой имеет 7 нейронов, по одному для каждого класса (интереса). Каждый нейрон выходного слоя возвращает вероятность принадлежности к соответствующему классу, что достигается использованием активационной функции сигмоида;
    \item регуляризация. Не стоит забывать о слоях «отсеивания» Dropout, которые помогают предотвратить переобучение путем случайного «выключения» нейронов во время обучения.
\end{enumerate}

Таким образом, структура нейронной сети определяется количеством слоев, количеством нейронов в каждом слое, выбором активационной функции и применением регуляризации для обеспечения лучшей обобщающей способности модели.

Для получения множества моделей с различной архитектурой используют специальные библиотеки-тюнеры, которые по заданным гиперпараметрам для каждого варианта обучают получившуюся сеть, после чего можно выбрать архитектуру сети, показавшую наибольшую точность.

Были выделены следующие параметры, которые учитывались при создании структуры нейронной сети:
\begin{itemize}
    \item num-hidden-layers – число скрытых слоев;
    \item num-neurons – число нейронов в слоях;
    \item activation – функция активации;
    \item dropout-rate – значение слоя Dropout;
    \item optimizer – определяет оптимизатор;
    \item learning-rate – скорость обучения.
\end{itemize}

Разработка нейронной сети производилась на языке Python с использованием библиотеки Keras. Для автоматического подбора параметров использовалась библиотека GridSearchCV.

Лучшие модели имеюют сходные параметры. После проведения эксперементов, было выявлено, что все они имеют по 3 скрытых слоя, одинаковую функцию активации ReLU, оптимизвтор и скорость обучения. Отличными параметрами являются число нейронов, которое у всех моделей разное, и значение слоя отсеивания, которое одинаково и равно 0,2 у 1 и 3 модели, а у 2 модели оно принимает значение 0,1. 

В таблице \ref{t:stat} представлен результат моделей.

% \begin{table}[h!]
%     \Large
%     \begin{threeparttable}
%         \caption{Результат модели}
%         \label{t:stat}
%         \centering
%         \begin{tabularx}{\textwidth}{|>{\centering\arraybackslash}X|>{\centering\arraybackslash}X|}
%             \hline
%             Точность & Ошибка \\
%             \hline
%             0,896    & 0,117  \\
%             \hline
%         \end{tabularx}
%     \end{threeparttable}
%     \vspace{\bottompaddingoftable}
% \end{table}

\begin{table}[h!]
    \Large
    \begin{threeparttable}
        \caption{Результат моделей}
        \label{t:stat}
        \centering
        \begin{tabularx}{\textwidth}{|>{\centering\arraybackslash}X|>{\centering\arraybackslash}X|>{\centering\arraybackslash}X|>{\centering\arraybackslash}X|}
            \hline
            Метрики \textbackslash Модели   &   Модель 1            &   Модель 2            &   Модель 3            \\
            \hline
            Параметры                       &   1-20, 2-20, 3-20    &   1-35, 2-30, 3-20    &  1-30, 2-20, 3-25     \\
            \hline
            Точность                        &   0,869               &   0,834               &   0,823               \\
            \hline
            Ошибка                          &   0,117               &   0,130               &   0,174               \\
            \hline   
        \end{tabularx}
    \end{threeparttable}
    \vspace{\bottompaddingoftable}
\end{table}



На рисунке~\ref{f:ns} представлена структура лучшей модели.



\begin{figure}[h!t]
    \centering
    \vspace{\toppaddingoffigure}
    \includegraphics[width=0.45\textwidth]{ns}
    \caption{Структура нейронной сети}
    \label{f:ns}
\end{figure}

\newpage

Из рисунка~\ref{f:ns} видно, что полученная модель состоит из:
\begin{itemize}
    \item входного слоя с 30 нейронами;
    \item 3-х полносвязных слоев с 20 нейронами;
    \item 3 слоев Dropout с коэффициентом 0.2;
    \item выходного слоя с 7 нейронами.
\end{itemize}
Полносвязные и Dropout слои чередуются.

\subsubsection{Разработка модуля}

Основной модуль должен получить от пользователя информацию о модели автомобиля и возрасте владельца. На основе этих данных, использую обученную модель, должен предсказать возможные интересы человека. Для считывания модели и возраста на окне необходимо расположить 2 поля для ввода. Результат работы проще воспринимать в таблице, пример которой представлен в таблице\ref{t:proc}.

\begin{table}[h!]
    \large
    \begin{threeparttable}
        \caption{Пример форматирования результата}
        \label{t:proc}
        \centering
        \begin{tabularx}{\textwidth}{|>{\centering\arraybackslash}X|>{\centering\arraybackslash}X|>{\centering\arraybackslash}X|>{\centering\arraybackslash}X|>{\centering\arraybackslash}X|>{\centering\arraybackslash}X|>{\centering\arraybackslash}X|}
            \hline
            Искусство & Спорт   & Книги/ Фильмы & Наука   & Путешест\-вия & Кулинария & Политика \\
            \hline
            93.00\%   & 97.30\% & 68.61\%       & 71.92\% & 0.34\%        & 3.82\%    & 92.60\%  \\
            \hline
        \end{tabularx}
    \end{threeparttable}
    \vspace{\bottompaddingoftable}
\end{table}

Исходя из необходимых компонентов, которые должны быть на экране, можно создать макет экранной формы. Он представлен на рисунке~\ref{f:maket}.

\begin{figure}[h!]
    \centering
    \vspace{\toppaddingoffigure}
    \includegraphics[width=0.55\textwidth]{maket}
    \caption{Макет экранной формы}
    \label{f:maket}
\end{figure}

Рассмотрим алгоритм работы модуля. Схема алгоритма представлена на рисунке~\ref{f:neuro-alg}.

\begin{figure}[h!]
    \centering
    \vspace{\toppaddingoffigure}
    \includegraphics[width=0.45\textwidth]{neuro-alg}
    \caption{Алгоритм модуля}
    \label{f:neuro-alg}
\end{figure}

Рассмотрим алгоритм подробнее:
\begin{enumerate}
    \item  инициализация интерфейса. Модуль создает графический интерфейс. Он состоит из окна, содержащего поля для ввода модели и возраста, кнопки для выполнения предсказания и таблицы для отображения результатов;
    \item  считывание данных. Пользователь вводит данные в поля "Модель" и "Возраст";
    \item  обработка введенных данных. Данные из полей ввода предварительно обрабатываются таким же образом, как и обрабатывались данные, использующиеся для обучения нейронной сети;
    \item  получение предсказаний. Введенные данные (модель и возраст) передаются в обученную модель для выполнения предсказания интересов. Результаты предсказаний возвращаются в виде вероятностей принадлежности к каждой из категорий интересов;
    \item  отображение результатов. После получения результатов предсказаний, проценты принадлежности к каждой категории интересов отображаются в таблице. Каждый столбец таблицы соответствует одной из категорий интересов;
    \item  завершение работы интерфейса. После завершения работы с интерфейсом пользователь может закрыть окно, нажав на кнопку закрытия или продолжить работу;
\end{enumerate}


\section*{Выводы}

В данном разделе был рассмотрен процесс проектирования разрабатываемого модуля. Будет определен функционал и особенности. Кроме того, были разработаны алгоритмы функционирования, а также структура нейросети и самого модуля в целом.
